{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d7cfb2-089c-4aab-96c7-186a85b4ca49",
   "metadata": {},
   "source": [
    "# Nauczanie Maszynowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f8961-b845-4b24-a1d3-ab1c32400d01",
   "metadata": {},
   "source": [
    "## Dzień 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c52e2-e6fd-4084-b398-da4a688a3187",
   "metadata": {},
   "source": [
    "### 0. Wprowadzenie\n",
    "  - Prowadzący: dr Michał Korzycki\n",
    "  - Kwestie Organizacyjne\n",
    "  - Ankieta początkowa\n",
    "\n",
    "### 1. Co to jest uczenie maszynowe?\n",
    "  - Statystyka a uczenie maszynowe\n",
    "  - Rodzaje problemów\n",
    "  - Przykładowe metody\n",
    "  - Rodzaje błędów popełnianych przez algorytmy\n",
    "  - Ekosystem uczenia maszynowego w Pythonie\n",
    "\n",
    "### 2. Regresja liniowa\n",
    "\n",
    "  - Najprostsza metoda predykcyjna\n",
    "  - Od jednej zmiennej do wielu\n",
    "  - Wstępna obróbka danych\n",
    "  - Walidacja predykcji\n",
    "  - Interpretacja ważności parametrów\n",
    "\n",
    "### 3. Regresja logistyczna\n",
    "\n",
    "  - Przewidywanie kategorii\n",
    "  - Różnica pomiędzy klasyfikacją a regresją\n",
    "  - Walidacja predykcji\n",
    "  - Interpretacja ważności parametrów\n",
    "\n",
    "### 4. Klasyfikacja, użycie drzew \n",
    "\n",
    "  - Jako ogólna metoda do klasyfikacji\n",
    "  - Kluczowe różnice pomiędzy metodami liniowymi\n",
    "  - Zjawisko przeuczania (overfitting) i jak mu przeciwdziałać\n",
    "\n",
    "### 5. Inżyniera cech\n",
    "\n",
    "  - Operacje na prostych wartościach\n",
    "  - Wygładzanie Laplace'a\n",
    "  - Skalowanie wartości\n",
    "  - Zmienne kategoryczne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5a73d-881b-4f04-a7a7-3cdd08141309",
   "metadata": {},
   "source": [
    "## Dzień 2\n",
    "\n",
    "1. Walidacja krzyżowa\n",
    "2. Hiperparametry i Grid Search\n",
    "3. Drzewa Losowe\n",
    "4. XGBoost\n",
    "\n",
    "## Dzień 3\n",
    "\n",
    "1. Projekt\n",
    "2. Otwarte tematy\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da885c77-e7e3-4ca5-974e-766f26f7a801",
   "metadata": {},
   "source": [
    "# 1. Co to jest nauczanie maszynowe\n",
    "\n",
    "## Statystyka a Nauczanie Maszynowe\n",
    "\n",
    "![a](img/ml.webp)\n",
    "\n",
    "\n",
    "https://www.instagram.com/sandserifcomics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15053904-207b-49f3-aee3-1935a38f2797",
   "metadata": {},
   "source": [
    "![](img\\danger.png)\n",
    "\n",
    "http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram\n",
    "\n",
    "\n",
    "- __*Statystyka*__ zajmuje się __*opisem*__ danych\n",
    "- __*Nauczanie maszynowe*__ zajmuje się __*predykcją*__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784c330-24b0-4016-aeae-0242224a2bd6",
   "metadata": {},
   "source": [
    "># Uczenie maszynowe, samouczenie się maszyn albo systemy uczące się (ang. machine learning) – obszar sztucznej inteligencji poświęcony algorytmom, które poprawiają się automatycznie poprzez doświadczenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bc479-50ff-4f63-98f9-d708681bd879",
   "metadata": {},
   "source": [
    "# Podział Sztucznej inteligencji ze względu na narzędzia:\n",
    "\n",
    "![AI](img\\AI1.png)\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Machine_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0d78a-8ad2-490c-8a44-1ec3d5843022",
   "metadata": {},
   "source": [
    "---\n",
    "## Ekosystem uczenia maszynowego w Pythonie\n",
    "\n",
    "- Jupyter - jako środowisko pracy\n",
    "  - Alternatywa: Google Collab\n",
    "  - Wersja: Anaconda - duży pakiet\n",
    "- Scikit Learn - jako biblioteka do nauczania maszynowego\n",
    "  - Alternatywa: TensorFlow do algorytmów opartych o Sieci Neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a810056-f14e-4866-9795-a69005b63dff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Rodzaje problemów w Nauczaniu Maszynowym\n",
    "\n",
    "- Nauczanie z nadzorem (_supervised_)\n",
    "- Nauczanie bez nadzoru (_unsupervised_)\n",
    "- Nauczanie ze wzmocnieniem (_reinforcement_)\n",
    "\n",
    "## Nauczanie Maszynowe bez nadzoru\n",
    "- Przykłady problemów:\n",
    "  - Klasteryzacja\n",
    "  - Reguły asocjacyjne\n",
    "  - Algorytmy rekomendacyjne\n",
    "\n",
    "## <span style=\"color: cyan\">Nauczanie Maszynowe z nadzorem</span>\n",
    "- <span style=\"color: cyan\">__*Klasyfikacja*__</span> \n",
    "    - rozpoznawanie kategorii: \n",
    "      - np. chory/zdrowy, spam/nie-spam\n",
    "    - wynikiem jest __*kategoria*__</span>\n",
    "- <span style=\"color: cyan\">__*Regresja*__</span>\n",
    "    - interpolacja/ekstrapolacja funcji ciągłej \n",
    "      - np. predykcja ceny na podstawie parametrów\n",
    "    - wynikiem jest __*wartość*__\n",
    "\n",
    "---\n",
    "​\n",
    "### Nauczanie Maszynowe z nadzorem\n",
    "\n",
    "Dla zmiennych tłumaczących `X` szukamy funkcji `f` która jak najlepiej odzwierciedli nam dane tłumaczone `y`\n",
    "​\n",
    "$$ \n",
    "y \\approx f (X)\n",
    "$$\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde73da-450c-4f27-b684-213cbf3c5044",
   "metadata": {},
   "source": [
    "# Rodzaje błędów popełnianych przez algorytmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3cd85-480f-4f74-90f4-2fba7940617d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"dark_background\")\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91ad42-6dcf-4dad-99d4-a9006f0e8a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"dark_background\")\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x))\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, x-0.6*x*x, color=\"g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb0607-8f47-4140-97a6-79cb3da0cfe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x));\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, x-0.6*x*x, color=\"g\")\n",
    "plt.plot(x, .75*x-0.3, color=\"y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcced984-8910-4654-954b-1e3fc7e13fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "x = np.linspace(-10, 10, 50)\n",
    "plt.scatter(x, x-0.5*np.abs(x))\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, x-0.6*x*x, color=\"g\")\n",
    "plt.plot(x, 0.75*x-0.3, color=\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a36e6e-2a30-420d-81bb-6dc0e6c4c7a6",
   "metadata": {},
   "source": [
    "## Kompromis między obciążeniem a wariancją\n",
    "### ang. *bias-variance tradeoff*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b91c32-7a29-48fd-ad33-0f443d4b4b3f",
   "metadata": {},
   "source": [
    "# $$Bias~[~\\hat{f}(x)~] = E~[~\\hat{f}(x)~] - f(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8f3a8-afe9-4da8-924e-c7e2b5487ac1",
   "metadata": {},
   "source": [
    "# $$Var~[~\\hat{f}(x)~] = E~[~\\hat{f}(x)^2~] - E~[~\\hat{f}(x)~]^2$$\n",
    "\n",
    "https://pl.wikipedia.org/wiki/Kompromis_mi%C4%99dzy_obci%C4%85%C5%BCeniem_a_wariancj%C4%85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c630dff-463a-43a6-ab41-347a8fe369cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def color_green_red(val):\n",
    "    color = 'red' if val.find('False') > -1 else 'green'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "data = {\"prediction\": [\"positive\", \"negative\"], \"positive\": [\"True Positive\", \"False Negative\"], \"negative\": [\"False Positive\", \"True Negative\"] }\n",
    "df = pd.DataFrame(data).set_index(\"prediction\")\n",
    "df.columns=pd.MultiIndex.from_tuples([(\"actual\", \"positive\"), (\"actual\", \"negative\")])\n",
    "df.style.applymap(color_green_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b2676-30f9-4569-a208-3721299a5c33",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Jak sobie z tym radzi Nauczanie Maszynowe ? Stosując:\n",
    "- #### Regularyzacje (prostsze modele)\n",
    "- #### Sprawdzian kryżowy (__*cross-validation*__)\n",
    "- #### Bagging/Boosting\n",
    "- #### Metody Zespołowe\n",
    "- #### Optymalizacja kreyteriów informacyjnych\n",
    "- #### Etc. Etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e7d3-a423-4658-b124-c6417547c9e9",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Regresja liniowa\n",
    "\n",
    "  - Najprostsza metoda predykcyjna\n",
    "  - Od jednej zmiennej do wielu\n",
    "  - Wstępna obróbka danych\n",
    "  - Walidacja predykcji\n",
    "  - Interpretacja ważności parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260bf270-ae63-44e8-9bbc-5fd92f58de9d",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dd4f8-7f8a-4966-9b63-f467c2591d05",
   "metadata": {},
   "source": [
    "## Proces nauczania w Machine Learning\n",
    "\n",
    "1. Przygotowanie danych\n",
    "2. Podział danych\n",
    "3. Budowanie modelu\n",
    "4. Test dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e368500-1a6d-487e-be56-549e402cc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "houses = pd.read_csv(\"data/houses/train.csv\")\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ffde7d-6616-4fc2-89d4-b356e573ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c3fcd-4455-4a19-aa7d-7540ffa34792",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"GrLivArea\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d428d8-0f1f-4391-9d0a-2b3a4d378a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"TotalBsmtSF\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa0b6a-6251-450c-966a-4b5c29037257",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"OverallQual\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c04ad1-fc29-4f6f-b80a-41bebac368e6",
   "metadata": {},
   "source": [
    "# $ y = \\epsilon + \\beta X $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3989b-5b80-464e-97d2-e92419f683fe",
   "metadata": {},
   "source": [
    "## $ \\epsilon$ - intercept \n",
    "## $ \\beta$ - coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3fb4e-513a-43e8-8434-1778ab9efb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd89d89-ffb0-4f5d-ba95-0d1c4a8998f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = houses[[\"GrLivArea\", \"TotalBsmtSF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f904e-b0e0-4c89-ac99-8a75861f1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283297c-cdc9-4bfc-befd-b5b5544c55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = houses[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a3dca-1639-4854-b97a-ec55c573989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b7130-08a8-427d-97d1-54eacaeb3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f2dd4-70e3-45ce-9373-8b1204955e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bb461-89fc-49cc-a4f1-d34db9c1ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff05a44-d12e-4125-aa3d-6ed011f6ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(np.array([[1515.463699, 1057.429452]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e2220-1bcf-44e8-81d7-c65d0c55d002",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea01bf-0d34-45a9-9e2e-a199e063bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed503f-ba50-42dc-8172-8aa25072285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc91c0-b4fa-4326-82c5-7a8f0fd852f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9bf9c-39c3-4334-a69b-c8e22b0405f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fd828-291b-4305-9570-3b267e935bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828be44c-2fea-4029-93d3-23dfa0d47fff",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: magenta\">Ćwiczenie - dodać jakość nieruchomości i sprawdzić czy score się poprawił</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503cd0e-65c1-4dcb-b3bb-97dff30992fb",
   "metadata": {},
   "source": [
    "## 3. Regresja logistyczna¶\n",
    " - Przewidywanie kategorii\n",
    " - Różnica pomiędzy klasyfikacją a regresją\n",
    " - Walidacja predykcji\n",
    " - Interpretacja ważności parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f992fa5-6be2-499f-a6f1-d6cb2210e381",
   "metadata": {},
   "source": [
    "# $$ p(x) = \\frac{1}{1+e^{-(\\epsilon + \\beta x)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15397a-5c64-4695-8c51-d9d9ae264e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"dark_background\")\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, 1/(1+np.exp(-(0+6*x))), color=\"g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cef707-8f98-41b5-8280-2da9f3cecdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8201c95-f15f-4f2c-8346-90fdcabf82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.predict(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628b13d-cdb8-45f2-b050-fafe2a60e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f867933-5b50-4636-9e43-a8c2e9258c4e",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Klasyfikacja, użycie drzew\n",
    " - Jako ogólna metoda do klasyfikacji\n",
    " - Kluczowe różnice pomiędzy metodami liniowymi\n",
    " - Zjawisko przeuczania (overfitting) i jak mu przeciwdziałać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb6284-8a93-450c-9af7-360e8507fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "iris = load_iris()\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = clf.fit(X, y)\n",
    "plt.figure(figsize=(18,12))\n",
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab41f3c-be85-46e9-94b6-ba2548e5cb10",
   "metadata": {},
   "source": [
    "![PrecisionRecall](img\\Precisionrecall.svg.png)\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd20e2-dc30-461f-a219-b4dd362ee00b",
   "metadata": {},
   "source": [
    "Przykład:\n",
    "    \n",
    "- 990 \"ham\"\n",
    "- 10 \"spam\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac23ad6-8c2b-4363-ad8c-8151ac9ba298",
   "metadata": {},
   "source": [
    "Accuracy - dokładność - % prawidłowych odpowiedzi\n",
    "\n",
    "- \"Wszystko ham\" - 99%\n",
    "\n",
    "Precision - precyzja - jaki % poprawności odpowiedzi (błedy pierwszego rodzaju)\n",
    "\n",
    "- \"Wszystko ham\" - 99% w ham, 0% w spam\n",
    "\n",
    "Recall - zupełność - jaki % poprawnych znalazł (błedy pierwszego rodzaju)\n",
    "\n",
    "- \"Wszystko ham\" - 100% w ham, 0% w spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9786a0f-3a5b-4817-9edc-199651e0b8ad",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fcdab-ee20-4ced-ad4a-a31d74cb1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403bb56-3089-4614-89ef-89d03d53ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1f597-d711-48e9-ac8b-e394d7ea5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'v1':'class_label', 'v2':'message'}, inplace = True)\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc1155-6a0e-4f39-9223-66cab8f52dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5055a1-c190-4a4e-b42d-6bdbfffbe849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as ab\n",
    "import numpy as np\n",
    "labels = ['ham', 'spam']\n",
    "counts = [4825, 747]\n",
    "ypos = np.arange(len(labels)) #converting text labels to numberic value, 0 and 1\n",
    "ypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10593f0-b02f-4942-9be5-40bc2c1ce55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.xticks(ypos, labels)\n",
    "ab.xlabel(\"class label\")\n",
    "ab.ylabel(\"Frequency\")\n",
    "ab.title(\"# of spam and ham in dataset\")\n",
    "ab.bar(ypos, counts, color=[\"g\", \"r\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6e854-2ec6-40a8-b0ad-1faaed241d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'] = df['class_label'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cf23d-f7d5-484b-bb0d-096f32025cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b10293-124c-4cf4-9779-3f0b02ee41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['message'], df['class_label'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e6787-a305-4a7e-a4d5-f220491ce148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows in test set: ' + str(x_test.shape))\n",
    "print('rows in train set: ' + str(x_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86b41a-4163-434c-969e-8e4d2b00032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 = df[df['class_label']==0]\n",
    "df_class_1 = df[df['class_label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad183c9-0fbe-47b4-aca8-3977b0634ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92fd79-1432-48c8-87ee-75b7bd291716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046f32c-dbc2-4f82-87d1-552a8fe9422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_test = df_class_0.sample(100)\n",
    "df_class_1_test = df_class_1.sample(100)\n",
    "df_class_0 = df_class_0.drop(df_class_0_test.index)\n",
    "df_class_1 = df_class_1.drop(df_class_1_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e53955-8e95-4dc4-9149-417b809b92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6355b-b79c-4fec-b6ad-704226a8a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7d224-5107-4164-92e1-7f1ace01dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f5e5a-2bbd-453e-b6e2-0fcc81e09fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204840b8-7a1b-4395-a582-39f12d933840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_class_0_test, df_class_1_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a771a-ec83-41ec-aa3f-90476f04021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_over = pd.concat([df_class_0, df_class_1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0468a1-e51a-4d95-ba50-5d73348dfac1",
   "metadata": {},
   "source": [
    "## Robimy OVERSAMPLING (dokładamy do mniejszej klasy powielone wartości)\n",
    "#### moglibyśmy zrobić UNDERSAMPLING (usuwamy z większej klasy)\n",
    "#### albo wogóle dołożyć SYNTETYCZNE dane (\"sztuczne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38aa6ad-0fc6-4d9a-b398-af1d532e7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(df_class_0.shape[0], replace=True)\n",
    "df_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_over.class_label.value_counts())\n",
    "\n",
    "df_over.class_label.value_counts().plot(kind='bar', title=\"# of spam and ham in dataset\", color=[\"g\", \"r\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47323f8-d3eb-4915-a5f9-0f6c8587c03e",
   "metadata": {},
   "source": [
    "---\n",
    "## Klasyfikacja niezbalansowanych zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93570e-802a-40fe-8305-5852efdc0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_not_over['message']\n",
    "y_train=df_not_over['class_label']\n",
    "x_test = df_test[\"message\"]\n",
    "y_test = df_test[\"class_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55768ad9-7c10-4bea-82cc-374b0214d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = x_train.tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "input= data ,  \n",
    "lowercase=True,      \n",
    "stop_words='english',\n",
    "min_df=2\n",
    ")\n",
    "\n",
    "features_train_transformed = vectorizer.fit_transform(data)  \n",
    "features_test_transformed  = vectorizer.transform(x_test) \n",
    "df_vectorized = pd.DataFrame(features_train_transformed.toarray(), columns = vectorizer.get_feature_names())\n",
    "df_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10df8e3-64a8-4c60-a89d-0751f5682932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fd5fa-9587-43c9-9ca8-11a854e2034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c9889-f46a-4676-bee9-503d87c85356",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classifier.predict(features_test_transformed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "actual = y_test.tolist()\n",
    "predicted = labels\n",
    "results = confusion_matrix(actual, predicted)\n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted) )\n",
    "score_2 = f1_score(actual, predicted, average = 'binary')\n",
    "print('F-Measure: %.3f' % score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afd8cd-1db6-48e2-b99e-6e5bec8bd406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                results.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     results.flatten()/np.sum(results)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(results, annot=labels, fmt='', cmap='Reds');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015abd3c-f291-4248-bcfb-cd33faa3bae7",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['message'], df['class_label'], test_size = 0.3, random_state = 0)\n",
    "print('rows in test set: ' + str(x_test.shape))\n",
    "print('rows in train set: ' + str(x_train.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0185602-80c0-49c8-ae04-8933665e6006",
   "metadata": {},
   "source": [
    "x_train_class_0 = df[df['class_label']==0]\n",
    "x_train_class_1 = df[df['class_label']==1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf852ac3-6b06-4683-83f7-ad81ce04e0ee",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.3, random_state = 0)\n",
    "print('rows in test set: ' + str(test.shape))\n",
    "print('rows in train set: ' + str(train.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb29112-b4a5-4c8f-b683-171c53657ae9",
   "metadata": {},
   "source": [
    "train_class_0 = train[train['class_label']==0]\n",
    "train_class_1 = train[train['class_label']==1]\n",
    "test_class_0 = test[test['class_label']==0]\n",
    "test_class_1 = test[test['class_label']==1]\n",
    "\n",
    "print('rows in train class 0 set: ' + str(train_class_0.shape))\n",
    "print('rows in train class 1 set: ' + str(train_class_1.shape))\n",
    "print('rows in test class 0 set: ' + str(test_class_0.shape))\n",
    "print('rows in test class 1 set: ' + str(test_class_1.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84789f-7a3b-45e1-a1ea-7d612cb11c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(df_class_0.shape[0], replace=True)\n",
    "print('Random over-sampling:')\n",
    "print('rows in train class 1 set: ' + str(df_class_1_over.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904d3f3-106c-4072-91a8-447b3e88a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows in train class 0 set: ' + str(df_class_0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f51424-746d-4053-b6b9-bd701f30e9cc",
   "metadata": {},
   "source": [
    "---\n",
    "## Klasyfikacja zbalansowanych zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640936d-e237-45e4-b4e5-5ea2b64412fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007bc80f-741c-4c39-8fc1-4e0d2ebbaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data['message']\n",
    "y_train=data['class_label']\n",
    "x_test = df_test[\"message\"]\n",
    "y_test = df_test[\"class_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00afe2c-b4a2-4349-af61-7d7f3fa3a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = x_train.tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "input= data,  \n",
    "lowercase=True,      \n",
    "stop_words='english',\n",
    "min_df=2\n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73171851-510a-4043-a0e2-885f1cd19311",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_transformed  = vectorizer.transform(x_test) \n",
    "df_vectorized = pd.DataFrame(features_train_transformed.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea63b3-c874-43a3-88e8-6f203f7d9d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f34c1c-6974-45c1-befe-c25ba48ba875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# train the model\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431fb7bb-6d55-4b71-bcf5-ae10f675263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3ad31-5432-4683-9513-f8511de21fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classifier.predict(features_test_transformed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "actual = y_test.tolist()\n",
    "predicted = labels\n",
    "results = confusion_matrix(actual, predicted)\n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted) )\n",
    "score_2 = f1_score(actual, predicted, average = 'binary')\n",
    "print('F-Measure: %.3f' % score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326cb01-2489-445c-83e6-8b8e51252ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                results.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     results.flatten()/np.sum(results)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(results, annot=labels, fmt='', cmap='Reds');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a17f4-987a-4c54-9b7c-3a02ca73f8f0",
   "metadata": {},
   "source": [
    "---\n",
    "## Dobór estymatorów\n",
    "\n",
    "![Dobór estymatorów](img\\ml_map.png)\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e6ef3-43df-4a01-a25b-c13c9e9105e1",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: magenta\">Ćwiczenie - zmienić klasyfikatory i sprawdzić czy score się poprawił</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922aeaa-835e-462a-bb51-cc52e4913b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm  import SVC\n",
    "\n",
    "classifier = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369379a8-19db-45cf-848d-79efa1972b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76efa2b0-e347-453c-9003-2f8c8d0ccaf0",
   "metadata": {},
   "source": [
    "---\n",
    "# Kompromis między jakością wyniku a interpretowalnością modelu\n",
    "\n",
    "# Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2728b6-a562-49a5-83d6-8d8e3dac4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "treeclf = tree.DecisionTreeClassifier(random_state=0)\n",
    "treeclf.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f585216-b1f6-4995-8b4a-652870f15918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ece8d5-ba46-483e-b476-2f6a8fc5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"classic\")\n",
    "plt.figure(figsize=(18,12))\n",
    "tree.plot_tree(treeclf, max_depth=5, feature_names=list(vectorizer.get_feature_names()), class_names=[\"ham\", \"spam\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8135c-0491-4546-b06d-19b2ff0d60bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Inżyniera cech\n",
    "\n",
    "---\n",
    "\n",
    "> ## The features you use influence more than everything else the result. \n",
    "> ## No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering.\n",
    ">## <div style=\"text-align: right\">— Luca Massaron Autor, Kaggle master</div>\n",
    "\n",
    "---\n",
    "\n",
    "> ## Coming up with features is difficult, time-consuming, requires expert knowledge.\n",
    "> ## \"_*Applied machine learning*_\" is basically feature engineering.\n",
    "> ## <div style=\"text-align: right\">— Andrew Ng</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5012935-e3e4-4d46-806c-ab3cf42f252e",
   "metadata": {},
   "source": [
    "---\n",
    "## \"*Kubełkowanie*\" - Binning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1446965-f449-42c2-a00a-f5de2e369949",
   "metadata": {},
   "source": [
    "\n",
    "### Histogram o stałej szerokości "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bd44d-9dac-452e-bdf8-696ecc494a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': np.random.randint(0, 100, 20)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83183490-c4ed-4665-965f-234e36ca3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8b206-2fb2-4d0b-a729-482b3f5c89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df.value, range(0, 105, 10), right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0264601-5a97-459e-9d77-97b6467367a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"{0} - {1}\".format(i, i + 9) for i in range(0, 100, 10)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2a80f-d2ea-4cef-9ac8-30799574a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8effc7-0d6e-4e0d-a3f9-0b08814993f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d683a65-ec17-469d-801f-c9b66ec7d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Group').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250d420-8708-4e46-acf1-0f307e6880c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'value': np.random.randint(0, 100, 20)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec7f64-1c9d-4223-a907-dc4345664d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ df.quantile(q) for q in [.25, .5, .75] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27493f57-09c9-4282-8ecd-1dc29d908298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df['value'], q=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8dd77-3daf-4c62-829a-bae556ca9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quartile']=pd.qcut(df['value'], q=4)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdbb58-33b6-44c7-9768-e1008366e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quartile']=pd.qcut(df['value'], q=4, labels=range(1,5))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba16cc-26ad-4878-8180-de976a089945",
   "metadata": {},
   "source": [
    "---\n",
    "# Skalowanie <a id=\"scale\"></a>\n",
    "\n",
    "- ## Logarytmiczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc7c9b-8a22-45f0-9026-1c5288f47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950f897-8874-422a-becc-9d0923d52f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adverts_29_04.csv', sep=';')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9c14a-dcaa-4d36-a2bb-0ce91df69a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price per m2'] = data['Cena'] / data['Wielkość (m2)']\n",
    "data = data.dropna(subset=['Price per m2'])\n",
    "data['Price per m2'] = data['Price per m2'].map('{:.0f}'.format)\n",
    "data[\"day\"] = data['Data dodania'].str[0:2]\n",
    "data[\"month\"] = data['Data dodania'].str[3:5]\n",
    "data[\"year\"] = data['Data dodania'].str[6:]\n",
    "df = data.drop(['Cena', 'Data dodania'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd034a-801e-4d01-a123-0e8928caa2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import log2\n",
    "\n",
    "data = pd.read_csv('data/adverts_29_04.csv', sep=';')\n",
    "data['Price per m2'] = data['Cena'] / data['Wielkość (m2)']\n",
    "data['Price per m2'] = data['Price per m2'].map('{:.0f}'.format)\n",
    "data = data.dropna(subset=['Price per m2'])\n",
    "\n",
    "data[\"Price log\"] = data['Wielkość (m2)'].apply(lambda x: log2(x)).map('{:.2f}'.format)\n",
    "data[\"day\"] = data['Data dodania'].str[0:2]\n",
    "data[\"month\"] = data['Data dodania'].str[3:5]\n",
    "data[\"year\"] = data['Data dodania'].str[6:]\n",
    "data = data.dropna(subset=['Price per m2'])\n",
    "df = data.drop(['Cena', 'Data dodania'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2bc25-9aaa-4557-adbb-e334ae282cb6",
   "metadata": {},
   "source": [
    "---\n",
    "- ## Min-Max Scaling\n",
    "\n",
    "#### Skaluje i przesuwa dane tak, by się mieściły między `0` a `1`\n",
    "\n",
    "### $$x_{minmax}^i = \\frac{x^i-min(x)}{max(x)-min(x)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10599c-2265-499a-b94a-56a59bf994e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Price per m2\", \"Wielkość (m2)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284025d-6121-4b43-8a33-33c7bfd519a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df[[\"Price per m2\", \"Wielkość (m2)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb0d8c-0b06-4bbb-a97f-47ccd795e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554be00-2007-4de4-9fa1-7cc15c9aad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler.transform(df[[\"Price per m2\", \"Wielkość (m2)\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d5a41-3a1c-4223-ba0e-72007bc3738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler.fit_transform(df[[\"Price per m2\", \"Wielkość (m2)\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a98c16-b884-49c9-899c-df71e930d43a",
   "metadata": {},
   "source": [
    "\n",
    "- ## Robust scaling\n",
    "#### Podobny to skalowania min-max tylko odejmuje medianę i skaluję odległością miedzy 1szym a 3cim kwartylem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6718e3-8f60-4368-8a62-f5a6cefd1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "pd.DataFrame(scaler.fit_transform(df[[\"Price per m2\", \"Wielkość (m2)\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b42bc5-a8bc-490e-870f-0cd0fa3f1945",
   "metadata": {},
   "source": [
    "\n",
    "- ## Standaryzacja\n",
    "\n",
    "#### Standaryzacja polega na sprowadzeniu dowolnego rozkładu normalnego do rozkładu standaryzowanego o wartości oczekiwanej `0` i odchyleniu standardowym `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcfc6f-0add-4817-aaff-bffd76f951c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pd.DataFrame(scaler.fit_transform(df[[\"Price per m2\", \"Wielkość (m2)\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e736450-767f-4b96-ab9b-a17c8145371a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# UWAGA\n",
    "\n",
    "##  <span style=\"color: red\">NIE</span> zamieniać danych <span style=\"color: cyan\">RZADKICH (dużo zer)</span> w <span style=\"color: cyan\">GĘSTE (mało zer)</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844b8a1-d946-4b98-ae87-6217ef19464e",
   "metadata": {},
   "source": [
    "\n",
    "## Wygładzanie Laplace'a\n",
    "\n",
    "\n",
    "- ### Dodaj `1` do liczników (zaczynaj od `1` a nie `0`)\n",
    "- ### Uodparnia model na pomijanie całkowite mało prawdopodobnych zdarzeń\n",
    "- ### Dobrze radzi sobie z liczeniem __*względnych*__ wartości \n",
    "\n",
    "## Przykład: rzut monetą asymetryczną\n",
    "\n",
    "### $n_0$ - ile razy wypadła  \"reszka\"\n",
    "### $n_1$ - ile razy wypadł \"orzeł\"\n",
    "\n",
    "### Estymator: \n",
    "### $$\\hat{p} = \\frac{n_0+1}{n_0 + n_1 + 2}$$\n",
    "### jest lepszy (mniejszy błąd średnio-kwadratowy) od\n",
    "### Estymatora: $$\\hat{p} = \\frac{n_0}{n_0 + n_1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb268a0-79b4-4184-a717-2f57ac685f6b",
   "metadata": {},
   "source": [
    "---\n",
    "# Zmienne kategoryczne <a id=\"cat\"></a>\n",
    "\n",
    "##  Indeksacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6d2f5-6397-4d2c-bc0b-150f9c53483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "label_encoded = df\n",
    "\n",
    "label_encoded['Location_Cat'] = labelencoder.fit_transform(label_encoded['Lokalizacja'])\n",
    "label_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872109e-58fa-4675-a370-87f4390f204b",
   "metadata": {},
   "source": [
    "---\n",
    "## __*One-hot encoding*__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a32129-b6c9-49ea-a447-26da4a7acfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc_df = pd.DataFrame(enc.fit_transform(label_encoded[['Location_Cat']]).toarray())\n",
    "\n",
    "one_hot_data = label_encoded.join(enc_df)\n",
    "one_hot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7057a-3aaf-46a0-a953-9cc6c9749e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_df = pd.get_dummies(df, columns=['Lokalizacja'])\n",
    "dum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e56e3-33e5-48ee-962c-447d8cca3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_df = pd.get_dummies(data, columns=['Lokalizacja', 'Na sprzedaż przez', 'Rodzaj nieruchomości', 'Liczba pokoi', 'Liczba łazienek', 'Parking'])\n",
    "dum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24696755-8112-4c68-8b27-e88ec480b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b926436-c640-4b59-811c-57f71c5371a9",
   "metadata": {},
   "source": [
    "---\n",
    "## Porządek zmiennych kategorycznych\n",
    "\n",
    "![Clockface](img/clock.png)\n",
    "\n",
    "### zmieniamy na współrzędne \"wskazówek\"\n",
    "\n",
    "### $ m \\to ( \\sin{(\\frac{2\\Pi\\:m}{12})}, \\cos{(\\frac{2\\Pi\\:m}{12})} )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a665a5-cddd-4752-a3ec-7cfc3273aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7239a-5c66-43c6-903e-247fb5207417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['month_x'] = df['month'].apply(lambda x: np.sin(np.pi*int(x)/12))\n",
    "df['month_y'] = df['month'].apply(lambda x: np.cos(np.pi*int(x)/12))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9b1ff-48af-4521-852b-1bb8388904c9",
   "metadata": {},
   "source": [
    "---\n",
    "# Dzień 1 - Podsumowanie\n",
    "\n",
    "- ## Nauczanie maszynowe służy do <span style=\"color: cyan\">predykcji</span>\n",
    "- ## Musimy być świadomi kompromisów:\n",
    "  - ### Kompromis między obciążeniem i wariancją\n",
    "  - ### Kompromis między Dokładnością i zupełnością (patrz: F1)\n",
    "  - ### Kompromis między skutecznośćią a przeźroczystością modelu\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd35f31-ebb9-4d5f-b537-09b3fcf4e4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
